{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":110281,"databundleVersionId":13391012,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vector Search Interaction with Patient Files\nPatient records can be tricky, and navigating them can be tricky in healthcare. Nevertheless, it is crucial to be able to do so.\n\nIn theory, this is done with meticulous standards and making sure there is very clear terminology in symptoms and observations. In practice, this is not always the case. For doctors seeing a patient that has a lengthy record for the first time it can be hard to decipher the relevant parts of the file. Add inconsistent word use and suddently standard search functions become very difficult to use.\n\nUsing Vector Search and Embeddings, we can hope to fix this issue. By embedding the semantic meaning of a word, we no longer need to rely on exact word use, and other relevant reports can come through the search to enrich the search result.\n\nTo showcase this use case, I have made an AI agent that lets you filter for relevant parts of patient files from a public dataset. We will ask it things like \"Has this patient shown signs of dementia before?\" and be able to get results back of reports that might be relevant. Should, for example, there be an increase of dementia-related reports over the past 6 months or so, a medical expert might want to act on that.\n\nAs a technical challenge, I wanted to do this entire process with the BigQuery Python library.","metadata":{}},{"cell_type":"markdown","source":"# Data setup\nUsing a public dataset of fake patient data, we can extract patient reports from 20 ficticious patients. The setup of the dataset is a bit limited, but we will further enrich that later.\n\nPeople to process is set to 10 by default, but could in theory be bumped up if you're prepared to foot the bill. Similarly the reports per patient is limited; there are thousands of patients in this dataset each with hundreds of reports!","metadata":{}},{"cell_type":"code","source":"!pip install --quiet google-cloud-bigquery-storage #Reduces future errors and increases readability","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:34:34.211946Z","iopub.execute_input":"2025-09-22T12:34:34.212328Z","iopub.status.idle":"2025-09-22T12:34:38.195868Z","shell.execute_reply.started":"2025-09-22T12:34:34.212304Z","shell.execute_reply":"2025-09-22T12:34:38.194480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nPROJECT_ID = user_secrets.get_secret(\"GCP_PROJECT_ID\")\nDATASET_ID = 'concept_data'\nDATASET_TABLE = 'concept_content'\nDATASET_LOCATION = 'US' \n\nPATIENTS_TO_PROCESS = 10 #How many patients to grab from the public dataset\nREPORTS_PER_PATIENT = 50 #How many reports do you want to generate and embed per person?\n\nprint('Project ID and Database settings have been succesfully set.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:42:55.468709Z","iopub.execute_input":"2025-09-22T12:42:55.469057Z","iopub.status.idle":"2025-09-22T12:42:55.632800Z","shell.execute_reply.started":"2025-09-22T12:42:55.469032Z","shell.execute_reply":"2025-09-22T12:42:55.631943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First, we generate an empty BigQuery Dataset to later create our tables and models into. I default to setting the location to US, as newer models tend to be available there slightly earlier than in my area (Europe).","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\nfrom google.api_core import exceptions as api_exceptions\n\n#BigQuery Client\nclient = bigquery.Client(project=PROJECT_ID)\n\ntry:\n    #Basic Dataset params\n    dataset_ref = client.dataset(DATASET_ID)\n    dataset = bigquery.Dataset(dataset_ref)\n    dataset.location = DATASET_LOCATION\n    \n    #Send the dataset to the API for creation.\n    dataset = client.create_dataset(dataset)\n    print(f\"Dataset '{DATASET_ID}' created successfully in {DATASET_LOCATION}\")\nexcept api_exceptions.Conflict:\n    #Handle the case where the dataset already exists.\n    print(f\"Dataset '{DATASET_ID}' already exists. Skipping creation.\")\nexcept Exception as e:\n    #Handle other potential API errors.\n    print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:34:38.244201Z","iopub.execute_input":"2025-09-22T12:34:38.244499Z","iopub.status.idle":"2025-09-22T12:34:57.778297Z","shell.execute_reply.started":"2025-09-22T12:34:38.244475Z","shell.execute_reply":"2025-09-22T12:34:57.777223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that the empty dataset has been generated, we can put our own data into it.\n\nThis query takes the public dataset with patient reports, and extracts people and their associated reports. The dataset has a lot of tables, most of which frankly lacked the context for me to understand, but I grabbed the \"concepts\" as well as their start and end-date. This gives us the following setup;\n\n* The ID of the condition, and its ancestor (type of condition)\n* The start and end date of the condition\n* The content of the condition and its ancestor, combined into 1 string\n* 2 empty columns, to be used later\n* A UUID using BigQuery's FARM_FINGERPRINT function","metadata":{}},{"cell_type":"code","source":"#Import necessary libraries for BigQuery and data handling\nfrom google.cloud import bigquery\nimport pandas as pd\n\n#BigQuery Client\nclient = bigquery.Client(project=PROJECT_ID)\n\n#Query setup, joining tables together from the public dataset to create our own. Lacks a unique identifier, so we use FARM_FINGERPRINT to make one.\n# This query will create or replace the 'DATASET_TABLE' table in your dataset.\nquery = f\"\"\"\nCREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}` AS\nWITH RankedConditions AS (\n    SELECT\n        t1.person_id,\n        t1.condition_concept_id,\n        t3.ancestor_concept_id,\n        ANY_VALUE(t1.condition_start_date) AS condition_start_date,\n        ANY_VALUE(t1.condition_end_date) AS condition_end_date,\n        FORMAT('Condition Name: %s\\\\nAncestor Name: %s',\n               ANY_VALUE(t2.concept_name),\n               ANY_VALUE(t4.concept_name)) AS concept_details,\n        CAST(NULL AS STRING) AS generated_report,\n        CAST(NULL AS ARRAY<FLOAT64>) AS report_embeddings,\n        ROW_NUMBER() OVER(PARTITION BY t1.person_id ORDER BY ANY_VALUE(t1.condition_start_date)) AS row_num\n    FROM\n        `bigquery-public-data.cms_synthetic_patient_data_omop.condition_occurrence` AS t1\n    JOIN\n        (SELECT DISTINCT person_id FROM `bigquery-public-data.cms_synthetic_patient_data_omop.person` ORDER BY person_id LIMIT {PATIENTS_TO_PROCESS}) AS limited_persons\n        ON t1.person_id = limited_persons.person_id\n    JOIN\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept` AS t2\n        ON t1.condition_concept_id = t2.concept_id\n    JOIN\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept_ancestor` AS t3\n        ON t1.condition_concept_id = t3.descendant_concept_id\n    JOIN\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept` AS t4\n        ON t3.ancestor_concept_id = t4.concept_id\n    GROUP BY\n        t1.person_id,\n        t1.condition_concept_id,\n        t3.ancestor_concept_id\n)\nSELECT\n    FARM_FINGERPRINT(TO_JSON_STRING(STRUCT(person_id, condition_concept_id, ancestor_concept_id))) AS unique_id,\n    person_id,\n    condition_concept_id,\n    ancestor_concept_id,\n    condition_start_date,\n    condition_end_date,\n    concept_details,\n    generated_report,\n    report_embeddings\nFROM\n    RankedConditions\nWHERE\n    row_num <= {REPORTS_PER_PATIENT};\n\"\"\"\n\nprint(f\"Executing BigQuery query to create/replace table '{DATASET_TABLE}'...\")\n# Run the query\nquery_job = client.query(query)\n# Wait for the query to complete\nquery_job.result()\nprint(f\"Table '{DATASET_TABLE}' created/replaced successfully.\")\n\n#Querying the resulting table to show the data we are working with.\nprint(\"\\nFetching first 5 rows from the new table for verification...\")\nquery_results_sql = f\"\"\"\nSELECT *\nFROM `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}`\nLIMIT 5;\n\"\"\"\ndf_results = client.query(query_results_sql).to_dataframe()\n\nprint(\"First 5 rows of `{DATASET_TABLE}`:\")\nprint(df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:34:57.780467Z","iopub.execute_input":"2025-09-22T12:34:57.781307Z","iopub.status.idle":"2025-09-22T12:35:07.611469Z","shell.execute_reply.started":"2025-09-22T12:34:57.781279Z","shell.execute_reply":"2025-09-22T12:35:07.610507Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generating fully fletched SOAP reports\nInitially I worked with this data, but my results were frankly quite middling. This is because, as you can see in these first 5 rows; the Condition name and Ancestor Name combine to about... 4 words? It's hard to embed something meaningful out of this, when it is so tiny and the terms used are quite generic.\n\nTo fix this, we will use these keywords to generate our own ficticious patient reports. For this, I picked SOAP standard reporting - A standard medical protocol that gives incredibly consistent output. The generated SOAP reports are quite dense and contain a high standard of information, easily beating out the condition/ancestor combination I used earlier. Later, we will use these SOAP reports to create a proper vector search embedding.\n\nTo do this, we will need to to create the model that will generate these reports for us. Luckily, you can do that with a BigQuery query!","metadata":{}},{"cell_type":"code","source":"GENERATION_MODEL_NAME = \"report_generation\" #Set this to what you want the ML model to be named.\nGENERATION_MODEL_TYPE = \"gemini-2.5-flash-lite\" #What model do you want to use.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:35:07.612462Z","iopub.execute_input":"2025-09-22T12:35:07.612989Z","iopub.status.idle":"2025-09-22T12:35:07.617386Z","shell.execute_reply.started":"2025-09-22T12:35:07.612953Z","shell.execute_reply":"2025-09-22T12:35:07.616430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"full_model_name = f\"`{PROJECT_ID}.{DATASET_ID}.{GENERATION_MODEL_NAME}`\"\n\nmodel_generation_query = f\"\"\"\nCREATE OR REPLACE MODEL {full_model_name}\nREMOTE WITH CONNECTION DEFAULT\nOPTIONS(ENDPOINT = '{GENERATION_MODEL_TYPE}')\n\"\"\"\n\ntry:\n    # Execute the query\n    job = client.query(model_generation_query)\n    job.result()  # Wait for the job to complete\n    print(\"Model created successfully.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:35:07.618395Z","iopub.execute_input":"2025-09-22T12:35:07.618746Z","iopub.status.idle":"2025-09-22T12:35:11.031225Z","shell.execute_reply.started":"2025-09-22T12:35:07.618711Z","shell.execute_reply":"2025-09-22T12:35:11.029980Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that we have a model, we can use it to generate text with ML.GENERATE_TEXT. Using BigQueryML, we take the condition and ancestor from the data and add it to the CONCAT.\n\nThe prompt is inside the CONCAT statement as you can see; it explains the setup of a SOAP report, gives the concept_details, and then Gemini generates them. We then update our existing database's generated_report column with the output.\n\nWith the default settings of 10 people and 50 reports per, there should be 500 reports to generate split into batches of 100.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\nimport time\n\n# Initialize the BigQuery client\nclient = bigquery.Client(project=PROJECT_ID)\n\n#The update query to call the Gemini model for each row.\n#We'll use a `WHERE` clause to process only rows where the report is still NULL.\n#This prevents reprocessing the same data if the script is run again.\nupdate_query = f\"\"\"\nUPDATE `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}` AS t\nSET\n    t.generated_report = model_output.ml_generate_text_llm_result\nFROM\n    ML.GENERATE_TEXT(\n        MODEL `{PROJECT_ID}.{DATASET_ID}.{GENERATION_MODEL_NAME }`,\n        (\n            SELECT\n                \n                t.unique_id AS unique_row_id,\n                CONCAT(\n                    \"Generate a detailed and fictional patient progress note using the SOAP (Subjective, Objective, Assessment, Plan) format for the following patient data. \",\n                    \"Do not include any personal identifying information. Keep the tone informative and formal. Do not include date or time, they are noted elsewhere - only report the details of SOAP, and nothing else. \",\n                    \"Patient Data: \", t.concept_details,\n                    \"\\\\nSubjective Based on the patient's condition, describe the patient's chief complaint or subjective narrative of their symptoms.\",\n                    \"\\\\nObjective Based on the patient's condition, provide an objective description of the findings, such as physical examination results or lab work (create fictional but plausible details).\",\n                    \"\\\\nAssessment Formulate a differential diagnosis or an assessment of the patient's condition based on the subjective and objective information.\",\n                    \"\\\\nPlan Outline a plan for the patient's treatment, follow-up, and further testing.\"\n                ) AS prompt\n            FROM\n                `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}` AS t\n            WHERE\n                t.generated_report IS NULL\n            LIMIT 100\n        ),\n        STRUCT(\n            1024 AS max_output_tokens,\n            0.5 AS temperature,\n            TRUE AS flatten_json_output\n        )\n    ) AS model_output\nWHERE\n    t.unique_id = model_output.unique_row_id;\n\"\"\"\n\nprint(f\"Executing update query using BigQuery ML model '{GENERATION_MODEL_NAME }'...\")\n\n#Loop until all rows have been updated\nwhile True:\n    #Run the update query\n    query_job = client.query(update_query)\n\n    #Wait for the query to complete\n    query_job.result()\n\n    #Get the number of rows affected by the UPDATE statement\n    rows_affected = query_job.num_dml_affected_rows\n\n    print(f\"\\nUpdate completed. {rows_affected} reports generated and saved.\")\n\n    #If no rows were affected, we have processed all of them.\n    if rows_affected == 0:\n        print(\"All records have been updated. The process is complete.\")\n        break\n\n    #Pause briefly between loops to avoid rate-limiting issues.\n    time.sleep(1)\n\nprint(\"\\nFetching first 5 rows with the new generated reports for verification...\")\n\nverification_query = f\"\"\"\nSELECT\n    person_id,\n    concept_details,\n    generated_report\nFROM `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}`\nWHERE generated_report IS NOT NULL\nLIMIT 5;\n\"\"\"\n\ndf_results = client.query(verification_query).to_dataframe()\n\nprint(\"First 5 rows of `concept_content` with generated reports:\")\nprint(df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:35:11.032247Z","iopub.execute_input":"2025-09-22T12:35:11.032529Z","iopub.status.idle":"2025-09-22T12:38:52.729795Z","shell.execute_reply.started":"2025-09-22T12:35:11.032497Z","shell.execute_reply":"2025-09-22T12:38:52.728786Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We now have all our data! And its quite bolsterous too!","metadata":{}},{"cell_type":"markdown","source":"# Embedding our reports\nFor those unfamiliar, with Embeddings we 'vectorize' the words; this lets us store the meaning of a word rather than just the letters itself, which in turn lets you query for them later; vectorizing the word 'phone' will store it alongside similar words like 'telephone', 'mobile phone', or maybe even some phone brands. In a medical context, we're basically grouping similar reports together. When then asking a question, we will scoop up reports that are very close to the embedded version of what we are asking, thus getting only relevant reports back.\n\nLike before, we need to generate an ML model for this. I'll be using Google's own text-embedding model.","metadata":{}},{"cell_type":"code","source":"EMBEDDING_MODEL_NAME = \"embedding_generation\" #Set this to what you want the ML model to be named.\nEMBEDDING_MODEL_TYPE = \"text-embedding-005\" #What model do you want to use.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:24.834478Z","iopub.execute_input":"2025-09-22T12:44:24.834858Z","iopub.status.idle":"2025-09-22T12:44:24.839494Z","shell.execute_reply.started":"2025-09-22T12:44:24.834835Z","shell.execute_reply":"2025-09-22T12:44:24.838614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"full_model_name = f\"`{PROJECT_ID}.{DATASET_ID}.{EMBEDDING_MODEL_NAME}`\"\n\nmodel_generation_query = f\"\"\"\nCREATE OR REPLACE MODEL {full_model_name}\nREMOTE WITH CONNECTION DEFAULT\nOPTIONS(ENDPOINT = '{EMBEDDING_MODEL_TYPE}')\n\"\"\"\n\ntry:\n    # Execute the query\n    job = client.query(model_generation_query)\n    job.result()  # Wait for the job to complete\n    \n    print(\"Model created successfully.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:38:52.736738Z","iopub.execute_input":"2025-09-22T12:38:52.737117Z","iopub.status.idle":"2025-09-22T12:38:55.772532Z","shell.execute_reply.started":"2025-09-22T12:38:52.737090Z","shell.execute_reply":"2025-09-22T12:38:55.771217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that we have our model, we can create embeddings. For each row of our dataset, the content gets turned into embeddings and written back to our table. We can use the dedicated ML.GENERATE_EMBEDDING for this","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\nimport time\n\n# Initialize the BigQuery client\nclient = bigquery.Client(project=PROJECT_ID)\n\nmerge_query = f\"\"\"\nMERGE `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}` AS T\nUSING (\n  WITH ReportsToEmbed AS (\n    SELECT\n      t.unique_id,\n      t.generated_report AS content,\n      ROW_NUMBER() OVER() AS row_num\n    FROM\n      `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}` AS t\n    WHERE\n      t.generated_report IS NOT NULL AND (t.report_embeddings IS NULL OR ARRAY_LENGTH(t.report_embeddings) = 0)\n    LIMIT 100\n  ),\n  EmbeddingsWithId AS (\n    SELECT\n      ml_generate_embedding_result,\n      ROW_NUMBER() OVER() AS row_num\n    FROM\n      ML.GENERATE_EMBEDDING(\n        MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDING_MODEL_NAME}`,\n        (SELECT content FROM ReportsToEmbed ORDER BY row_num)\n      )\n  )\n  SELECT\n    r.unique_id,\n    e.ml_generate_embedding_result\n  FROM\n    ReportsToEmbed r\n  JOIN\n    EmbeddingsWithId e\n  ON\n    r.row_num = e.row_num\n) AS S\nON T.unique_id = S.unique_id\nWHEN MATCHED THEN\n  UPDATE SET T.report_embeddings = S.ml_generate_embedding_result;\n\"\"\"\n\nprint(f\"Embedding reports using the BigQuery ML model  and updating the '{DATASET_TABLE}' table...\")\n\n# Loop until all reports have been embedded\nwhile True:\n    #Run the MERGE query\n    query_job = client.query(merge_query)\n\n    #Wait for the query to complete\n    query_job.result()\n\n    #Get the number of rows affected by the MERGE statement\n    rows_affected = query_job.num_dml_affected_rows\n\n    print(f\"\\nMerge completed. {rows_affected} reports embedded and saved.\")\n\n    # If no rows were affected, all reports have been processed.\n    if rows_affected == 0:\n        print(\"All records have been embedded. The process is complete.\")\n        break\n\n    # Optional: Pause briefly between loops to avoid rate-limiting issues.\n    time.sleep(1)\n\nprint(\"\\nFetching first 5 rows with the new embeddings for verification...\")\n\nverification_query = f\"\"\"\nSELECT\n    person_id,\n    generated_report,\n    report_embeddings\nFROM `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}`\nWHERE report_embeddings IS NOT NULL\nLIMIT 5;\n\"\"\"\n\ndf_results = client.query(verification_query).to_dataframe()\n\nprint(\"First 5 rows of `concept_content` with generated embeddings:\")\nprint(df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:38:55.775030Z","iopub.execute_input":"2025-09-22T12:38:55.775307Z","iopub.status.idle":"2025-09-22T12:39:27.536986Z","shell.execute_reply.started":"2025-09-22T12:38:55.775285Z","shell.execute_reply":"2025-09-22T12:39:27.536066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We've now successfully embedded the content! This SQL query does the following:\n* Go through each row in our data\n* Grab the SOAP report, and generate embeddings for it using ML.GENERATE_EMBEDDING\n* Save that result to another column.\n\nAs you can see by the output, the report_embeddings are now entirely unreadable for humans but it is key to perform a similarity search.","metadata":{}},{"cell_type":"markdown","source":"# Querying our Embeddings.\nAs a proof of concept, we will now query a symptom against our data. Because our reports are done per person, we can query it for only 1 patient and see what reports are similar to what we asked. There are multiple ways to do this, but to stay on theme here I want to keep using BigQuery for it and use VECTOR_SEARCH function (I did initially also use ML.DISTANCE)\n\nFor a more Google-minded approach, look into Vector Search: https://cloud.google.com/vertex-ai/docs/vector-search/overview - This, in my opnion, only gets interesting with huge datasets. My preferred method is using the sklearn python library, however I have not done that at scale.\n\nOn top of the similarity search, I added a minimal_similarity treshold - this is to not waste the caretakers time by giving irrelevant results back. This is important in any and all Vector Searches, as the code as is will always try to return the highest ranking results even if they barely match at all.","metadata":{}},{"cell_type":"code","source":"query = \"Lower back problems\"\npatient_id = 1\nstart_date = \"2009-01-01\"\nend_date = \"2010-01-01\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:17.837211Z","iopub.execute_input":"2025-09-22T12:44:17.838264Z","iopub.status.idle":"2025-09-22T12:44:17.843074Z","shell.execute_reply.started":"2025-09-22T12:44:17.838228Z","shell.execute_reply":"2025-09-22T12:44:17.842216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom google.cloud import bigquery\n\nTOP_K_RESULTS = 3 #How many results we want returned\nMINIMAL_SIMILARITY = 0.6 #How good results have to be in order to be returned. \n\ndef perform_similarity_search_bigquery_ml(query, patient_id, start_date, end_date):\n    client = bigquery.Client(project=PROJECT_ID)\n\n    try:\n        print(f\"Performing similarity search using BigQuery ML for query: '{query}'\")\n\n        # The SQL query to generate the query embedding and perform the search\n        sql_query = f\"\"\"\n        SELECT\n          base.concept_details,\n          base.generated_report,\n          1 - distance AS cosine_similarity -- Convert cosine distance to similarity\n        FROM\n          VECTOR_SEARCH(\n            (\n              SELECT\n                *\n              FROM\n                `{PROJECT_ID}.{DATASET_ID}.{DATASET_TABLE}`\n              WHERE\n                person_id = @patient_id\n                AND condition_start_date >= @start_date\n                AND condition_end_date < @end_date\n            ),\n            'report_embeddings', -- The column to search, as a string literal\n            (\n              SELECT\n                ml_generate_embedding_result AS embedding\n              FROM\n                ML.GENERATE_EMBEDDING(\n                  MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDING_MODEL_NAME}`,\n                  (SELECT @query AS content)\n                )\n            ),\n            query_column_to_search => 'embedding', -- Named argument for the query column\n            top_k => @top_k_results, -- Named argument for top_k\n            distance_type => 'COSINE' -- Named argument for distance_type\n          )\n        WHERE\n          1 - distance >= @minimal_similarity \n        ORDER BY\n          cosine_similarity DESC;\n        \"\"\"\n        \n        #Configure the query with parameters to prevent SQL injection and ensure type safety\n        job_config = bigquery.QueryJobConfig(\n            query_parameters=[\n                bigquery.ScalarQueryParameter(\"query\", \"STRING\", query),\n                bigquery.ScalarQueryParameter(\"patient_id\", \"INT64\", patient_id),\n                bigquery.ScalarQueryParameter(\"start_date\", \"STRING\", start_date),\n                bigquery.ScalarQueryParameter(\"end_date\", \"STRING\", end_date),\n                bigquery.ScalarQueryParameter(\"top_k_results\", \"INT64\", TOP_K_RESULTS),\n                bigquery.ScalarQueryParameter(\"minimal_similarity\", \"FLOAT64\", MINIMAL_SIMILARITY),\n\n            ]\n        )\n\n        #Run the query\n        query_job = client.query(sql_query, job_config=job_config)\n\n        #Load the results directly into a DataFrame\n        results_df = query_job.to_dataframe()\n\n        if results_df.empty:\n            print(\"No matching concepts found for the given criteria.\")\n            return\n\n        # Display the results\n        print(f\"\\n--- Top Matching Concepts for query: '{query}' ---\")\n        for rank, row in results_df.iterrows():\n            print(f\"\\nRank {rank + 1}: Score = {row['cosine_similarity']:.4f}\")\n            print(f\"  Concept: {row['concept_details']}\")\n            print(f\"  Details: {row['generated_report']}\")\n            print(\"------------\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nperform_similarity_search_bigquery_ml(query=query, patient_id=patient_id, start_date=start_date, end_date=end_date)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:18.899805Z","iopub.execute_input":"2025-09-22T12:44:18.900141Z","iopub.status.idle":"2025-09-22T12:44:18.909912Z","shell.execute_reply.started":"2025-09-22T12:44:18.900120Z","shell.execute_reply":"2025-09-22T12:44:18.908936Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Like said before, we are keeping with the theme and using BigQueryML.\n\nA bit hard to describe as it's 1 big SQL statement, but we are doing the following:\n\n* Generating Embeddings for our Query, the same way we have done for our generated reports before. This makes them comparable to each other as they use the same embeddings/language.\n* Using VECTOR_SEARCH to compare this embedding to the embeddings from our table.\n* This performs a cosine similarity search to see how \"similar\" they are.\n* The top 3 reports then get returned to us.\nWith the default values, I know patient 1 suffers from lower back problems by looking through the data prior. Indeed, the highest returning scores from our vector search for our question relates to their back issues.","metadata":{}},{"cell_type":"markdown","source":"# Creating an Agent to call our function\nThis is all well and good, but this isn't usable for a medical professional. At least, the ones I've met aren't proficient in Python and BigQuery.\n\nUsing Gemini, we can interact with it and have it call our python functions when it deems appropiate. This is done using a concept called function calling - https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling\n\nIn the following code we specify a prompt and a patient to ask it about. We then create a Tool; this is the format that Gemini uses to do Function Calling. Assuming we ask a good enough question, Gemini will then recognize it and fill in the function arguments for us.\n\nThe code then executes the function with the params given by Gemini.","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"gemini-2.5-flash-lite\"\nPROMPT = \"Does this patient have a history with lower back problems?\"\nPATIENT_ID = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:02.310900Z","iopub.execute_input":"2025-09-22T12:44:02.311206Z","iopub.status.idle":"2025-09-22T12:44:02.316226Z","shell.execute_reply.started":"2025-09-22T12:44:02.311179Z","shell.execute_reply":"2025-09-22T12:44:02.315122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport json\nfrom google import genai\nfrom google.genai.types import (\n    FunctionDeclaration,\n    GenerateContentConfig,\n    Tool,\n)\n\nfrom google.cloud import bigquery\nimport time\n\nfrom kaggle_gcp import KaggleKernelCredentials\n\ntry:\n    # Get the credentials object from the Kaggle environment\n    credentials = KaggleKernelCredentials()\n\n    # Pass the credentials object directly to the genai.Client\n    client = genai.Client(\n        vertexai=True,\n        project=PROJECT_ID,\n        location=\"us-east1\",\n        credentials=credentials \n    )\n    print(\"GenAI client initialized successfully with Kaggle credentials.\")\nexcept Exception as e:\n    print(f\"Failed to initialize client with credentials: {e}\")\n    raise SystemExit(\"Exiting due to authentication failure.\")\n\ndef function_calling_agent():\n    #Define the tool for the model using the FunctionDeclaration and Tool classes.\n    get_similarity_search = FunctionDeclaration(\n        name='perform_similarity_search_bigquery_ml',\n        description='Performs a semantic similarity search on the medical report data to find patient reports that are similar to the question of the medical professional interacting with you.',\n        \n        #Function parameters are specified in JSON schema format\n        parameters={\n            \"type\": \"OBJECT\",\n            \"properties\": {\n                'query': {\"type\": \"STRING\", \"description\": 'The user\\'s search query.'},\n                'patient_id': {\"type\": \"STRING\", \"description\": 'The ID of the patient.'},\n                'start_date': {\"type\": \"STRING\", \"description\": 'The start date of the search range in YYYY-MM-DD format. If not given, assume 1970-01-01'},\n                'end_date': {\"type\": \"STRING\", \"description\": 'The end date of the search range in YYYY-MM-DD format. If not given, assume today'},\n            },\n            \"required\": ['query', 'patient_id', 'start_date', 'end_date'],\n        },\n    )\n\n    #Defining the tool itself to use the function\n    search_tool = Tool(function_declarations=[get_similarity_search])\n\n    #Create a user prompt that would naturally trigger the function call.\n    final_prompt = PROMPT + f\"\\nPatient ID: {PATIENT_ID}, current date: {time.strftime('%Y-%m-%d')}\" #Adding our other variables to the prompt.\n    print(\"Sending prompt to the model...\")\n    print(f'''As a reminder, prompt was \"{PROMPT}\"''')\n\n    #Generating the content now with all of our input. Temperature lets Gemini be a bit 'creative' with its output.\n    response = client.models.generate_content(\n        model=MODEL_NAME,\n        contents=final_prompt,\n        config=GenerateContentConfig(\n            tools=[search_tool],\n            temperature=0.3,\n        ),\n    )\n\n    #Check the response for a function call and execute it.\n    if response.function_calls:\n        print(\"\\nModel response contains a function call:\")\n        call = response.function_calls[0]\n        print(call)\n\n        #Get the Python functio to call\n        function_to_call = globals()[call.name]\n\n        #Execute the function with the arguments provided by the model.\n        function_result = function_to_call(**call.args)\n    else:\n        print(\"\\nModel did not return a function call.\")\n        print(f\"Model response: {response.text}\")\n\n\nfunction_calling_agent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:30.476228Z","iopub.execute_input":"2025-09-22T12:44:30.476503Z","iopub.status.idle":"2025-09-22T12:44:34.470517Z","shell.execute_reply.started":"2025-09-22T12:44:30.476483Z","shell.execute_reply":"2025-09-22T12:44:34.469713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As you can (hopefully) see, patient 1 does indeed have a history with back problems like we've seen earlier in our BigQueryML function.\nLet's try 1 more.","metadata":{}},{"cell_type":"code","source":"PROMPT = \"Did this patient have issues with diabetes through 2009?\"\nPATIENT_ID = 3\n\nfunction_calling_agent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:44:41.637378Z","iopub.execute_input":"2025-09-22T12:44:41.638412Z","iopub.status.idle":"2025-09-22T12:44:44.989267Z","shell.execute_reply.started":"2025-09-22T12:44:41.638380Z","shell.execute_reply":"2025-09-22T12:44:44.988039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Indeed, this patient suffered from diabetes. Reading the logging explains how Gemini has filled in the function parameters based on the year, and our results match that. \n\nNow for 1 final application;","metadata":{}},{"cell_type":"code","source":"PROMPT = \"Have there been dementia related symptoms since september 2009?\"\nPATIENT_ID = 4\n\nfunction_calling_agent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T12:39:41.459532Z","iopub.execute_input":"2025-09-22T12:39:41.459818Z","iopub.status.idle":"2025-09-22T12:39:45.177122Z","shell.execute_reply.started":"2025-09-22T12:39:41.459795Z","shell.execute_reply":"2025-09-22T12:39:45.176231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As you can see, no results. The similarity search tresholds filters them - in reality, this patient has only suffered from spinal issues and diabetes in this window.\n\nIf we were to say, deploy this to a Cloud Run (or Google's Agent Engine), we would now have a REST API Endpoint that can be called by any application to actually Vector Search through patient data!","metadata":{}},{"cell_type":"markdown","source":"# Conclusions\nHopefully I've been able to showcase the power of BigQueryML here. I was impressed that all of this functionality works within SQL; I was worried that this would have to be a video showcase of me going through bigquery and setting up all these things by hand (like for example, creating the Generation and Embedding Models), but luckily this was all possible with just BigQuery calls inside Kaggle. The speed of the BigQueryML calls also surprised me, especially the similarity search.\n\nI'm a big fan of embeddings in the medical sphere. I've worked in healthcare-related IT for a few years and the amount of administration and bulk that these nurses and other professionals need to go through is absurd. Hopefully we can, in the near future, assist them in this proces. The quality of our models will keep improving, and I think this can be a reality soon.\n\nThe lack of consistant language use inbetween organisations and programs can cause extra bloat in this administrative process. Embeddings and Classifications within GCP can realy alleviate these issues.\n\nIf I were to do this again, I would set up something more robust for the agent using Google's Agent Development Kit (ADK). It's elegant use of sub-agents would let you run a host of queries all within the same project while still having a clean project setup. That being said, I'm not sure how it would interact with a Kaggle Notebook and I would find it unrelated to the BigQuery usecase. Should I bring this to production, I will definitely read into it more.\n\nOutside of that, I would write something to reduce the verboseness of the SOAP reports - they're quite wordy, and it troubles the embeddings somewhat.","metadata":{}}]}